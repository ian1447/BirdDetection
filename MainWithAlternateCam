import cv2
import numpy as np
import time

#load Yolo
net = cv2.dnn.readNet("yolov4-tiny.weights","yolov4-tiny.cfg.txt")
classes = []
with open("coco.names.txt", "r") as f:
    classes = [line.strip() for line in f.readlines()]
layer_names = net.getLayerNames()
output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]

#load image
# img = cv2.imread("birds2.jpg")
# H, W = (img.shape[0], img.shape[1])

#load video

#for image resize
#img = cv2.resize(img, None, fx=0.4, fy=0.4)
# used to record the time when we processed last frame
prev_frame_time = 0

# used to record the time at which we processed current frame
new_frame_time = 0

exchange_camera = True
first_load = True
using_zero = True
on_repeat = True

while on_repeat:
    print("Change Camera")
    time_default = time.time()
    if first_load:
        cap = cv2.VideoCapture(0)
    elif not first_load:
        if using_zero:
            cap = cv2.VideoCapture(1)
            using_zero = False
        else:
            cap = cv2.VideoCapture(0)
            using_zero = True

    first_load = False
    while cap.isOpened():
        success, frame = cap.read()
        time_start = time.time()

        H, W = (frame.shape[0], frame.shape[1])
        height, width, channels = frame.shape

        blob =cv2.dnn.blobFromImage(frame, 0.00392, (416,416), (0,0,0), True, crop=False)
        net.setInput(blob)
        output = net.forward(output_layers)

        boxes = []
        confidences = []
        classIDs = []

        new_frame_time = time.time()

        fps = 1 / (new_frame_time - prev_frame_time)
        prev_frame_time = new_frame_time
        fps = int(fps)
        fps = str(fps)

        for out in output:
            for detection in out:

                scores = detection[5:]
                classID = np.argmax(scores)
                confidence = scores[classID]

                #classId == 14 means that it only reads detection of birds based on coco.names.txt
                if confidence > 0.3 and classID==14:
                    #insert function para sa motor
                    box = detection[0:4] * np.array([W, H, W, H])
                    (centerX, centerY, width, height) = box.astype('int')

                    x = int(centerX - (width / 2))
                    y = int(centerY - (height / 2))

                    box_centers = [centerX, centerY]

                    boxes.append([x, y, int(width), int(height)])
                    confidences.append(float(confidence))
                    classIDs.append(classID)

        #pwede na tang  tangon ug dli necessary ang video makita
        indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)
        font = cv2.FONT_HERSHEY_PLAIN
        for i in range(len(boxes)):
            for i in indexes:
                x,y,w,h = boxes[i]
                label = str(classes[classIDs[i]])
                cv2.rectangle(frame, (x,y), (x+w,y+h),(0,255,0),2)
                #forlabel
                cv2.putText(frame, label, (x,y+30),font,1,(255,255,0),1)

        cv2.putText(frame, fps, (7, 70), font, 3, (100, 255, 0), 3, cv2.LINE_AA)
        cv2.imshow("Image", frame) #hangtod ani
        #for video
        if cv2.waitKey(5) & 0xFF == ord('q'):
            on_repeat = False
            break
        if (time_start-time_default > 25):
            cv2.destroyAllWindows()
            break
